import os
import streamlit as st
import io
import random
from PIL import Image
import torch

from system.src.interface.controllers.chat_with_image import (
    load_model,
    predict_and_plot,
    preprocess_image,
    label_map,
    load_classify_model,
    preprocess_classify_image,
    ground_truth_labels
)


def generate_diagnosis(query: str) -> str:
    return f"Ph√¢n t√≠ch b·ªánh l√Ω t·ª´ c√¢u h·ªèi: \"{query}\""


def init_session_state():
    if 'selected_sample_image' not in st.session_state:
        st.session_state.selected_sample_image = None
    if 'uploaded_file' not in st.session_state:
        st.session_state.uploaded_file = None


def on_image_click(img_path):
    st.session_state.selected_sample_image = img_path
    st.session_state.uploaded_file = None


def render():
    init_session_state()
    st.subheader("üì¨ DermatoAI Studio: Messenger with image")
    st.markdown(
        "Vui l√≤ng nh·∫≠p c√¢u h·ªèi v√† t·∫£i ·∫£nh ho·∫∑c ch·ªçn ·∫£nh m·∫´u ƒë·ªÉ h·ªá th·ªëng ph√¢n t√≠ch.")

    st.subheader("üé≤ ·∫¢nh m·∫´u ng·∫´u nhi√™n t·ª´ th∆∞ m·ª•c d·ªØ li·ªáu h·ªá th·ªëng")

    image_dir = r"storage/ISIC2018_Task3_Training_Input"
    all_images = [os.path.join(image_dir, f) for f in os.listdir(image_dir)
                  if f.lower().endswith(('.png', '.jpg', '.jpeg'))]
    sample_images = random.sample(all_images, min(20, len(all_images)))

    cols = st.columns(5)
    for idx, img_path in enumerate(sample_images):
        with cols[idx % 5]:
            try:
                img = Image.open(img_path)
                st.image(img, use_container_width=True,
                         caption=os.path.basename(img_path))
                st.button(
                    "Th·ª≠ v·ªõi m·∫´u n√†y",
                    key=f"btn_{os.path.basename(img_path)}",
                    on_click=on_image_click,
                    args=(img_path,)
                )
            except Exception as e:
                st.error(f"L·ªói khi t·∫£i ·∫£nh: {e}")

    with st.form("diagnosis_form"):
        query = st.text_input("C√¢u h·ªèi v·ªÅ b·ªánh l√Ω")

        if st.session_state.selected_sample_image:
            st.success(
                f"‚úÖ ƒê√£ ch·ªçn ·∫£nh m·∫´u: {os.path.basename(st.session_state.selected_sample_image)}")
            if st.form_submit_button("H·ªßy ch·ªçn ·∫£nh m·∫´u"):
                st.session_state.selected_sample_image = None
                st.rerun()

        if not st.session_state.selected_sample_image:
            uploaded_file = st.file_uploader(
                "T·∫£i ·∫£nh v√πng da t·ªïn th∆∞∆°ng",
                type=["png", "jpg", "jpeg"],
                key="file_uploader"
            )
        else:
            uploaded_file = None

        submitted = st.form_submit_button("Ph√¢n t√≠ch")

    if submitted:
        if not query: pass

        if not st.session_state.selected_sample_image and not uploaded_file:
            st.warning("‚ùó B·∫°n c·∫ßn t·∫£i ·∫£nh ho·∫∑c ch·ªçn ·∫£nh m·∫´u.")
            return

        if st.session_state.selected_sample_image:
            try:
                with open(st.session_state.selected_sample_image, "rb") as f:
                    img_bytes = f.read()
                image_io = io.BytesIO(img_bytes)
                image = Image.open(image_io).convert('RGB')
                image_name = os.path.splitext(os.path.basename(
                    st.session_state.selected_sample_image))[0]
                st.image(
                    image, caption=f'·∫¢nh m·∫´u: {image_name}', use_container_width=True)
            except Exception as e:
                st.error(f"L·ªói khi ƒë·ªçc ·∫£nh m·∫´u: {e}")
                return
        else:
            img_bytes = uploaded_file.read()
            image_io = io.BytesIO(img_bytes)
            image = Image.open(image_io).convert('RGB')
            image_name = os.path.splitext(uploaded_file.name)[0]
            st.image(image, caption='H√¨nh ·∫£nh ƒë√£ t·∫£i l√™n ..',
                     use_container_width=True)

        with st.spinner("ƒêang ph√¢n lo·∫°i t·ªïn th∆∞∆°ng..."):
            try:
                model = load_classify_model(
                    r"storage/resnet18_isic2018_5_epochs.pth")
                input_tensor = preprocess_classify_image(image)
                with torch.no_grad():
                    outputs = model(input_tensor)
                    _, predicted = torch.max(outputs, 1)
                    class_id = predicted.item()
                    class_name = label_map.get(class_id, "Kh√¥ng r√µ")
            except Exception as e:
                st.error(f"L·ªói khi ph√¢n lo·∫°i: {e}")
                return

        true_class_id = ground_truth_labels.get(image_name, None)
        true_class_name = label_map.get(
            true_class_id, "Kh√¥ng r√µ") if true_class_id is not None else "Kh√¥ng r√µ"

        st.success(
            f"üìå K·∫øt qu·∫£ ph√¢n lo·∫°i t·ªïn th∆∞∆°ng => **{class_name}** (class label #{class_id})")
        st.info(
            f"‚úÖ Ground truth c·ªßa t·ªïn th∆∞∆°ng => **{true_class_name}** (class label #{true_class_id})")

        st.info("üîç ƒêang ph√¢n t√≠ch h√¨nh ·∫£nh...")
        try:
            model = load_model(
                "storage/deeplabv3_plus_pretrained_model_isic_2018.pth.tar")
            input_tensor, original_image = preprocess_image(image_io)
            result_buf, details = predict_and_plot(
                model, input_tensor, original_image)
            segmented_image_bytes = result_buf.getvalue()
        except Exception as e:
            st.error(f"L·ªói khi ph√¢n ƒëo·∫°n ·∫£nh: {e}")
            return

        st.subheader("üìä Th·ªëng k√™ t·ªïn th∆∞∆°ng chi ti·∫øt")

        col1, col2, col3 = st.columns(3)

        with col1:
            st.markdown("**Th√¥ng s·ªë c∆° b·∫£n**")
            st.markdown(
                f"- Di·ªán t√≠ch t·ªïn th∆∞∆°ng: **{details['lesion_area']} pixels**")
            st.markdown(
                f"- T·ª∑ l·ªá t·ªïn th∆∞∆°ng: **{details['lesion_ratio']:.2f}%**")
            st.markdown(
                f"- Chu vi v√πng t·ªïn th∆∞∆°ng: **{details['perimeter']:.2f} pixels**")
            st.markdown(
                f"- S·ªë v√πng t·ªïn th∆∞∆°ng ri√™ng bi·ªát: **{details['num_lesions']}**")
            st.markdown(f"- Aspect ratio: **{details['aspect_ratio']:.2f}**")

        with col2:
            st.markdown("**ƒê·∫∑c ƒëi·ªÉm h√¨nh d·∫°ng**")
            st.markdown(f"- Circularity: **{details['circularity']:.4f}**")
            st.markdown(f"- Solidity: **{details['solidity']:.4f}**")
            st.markdown(f"- Extent: **{details['extent']:.4f}**")
            st.markdown(
                f"- ƒê·ªëi x·ª©ng v√πng t·ªïn th∆∞∆°ng: **{details['symmetry']:.4f}**")
            st.markdown(
                f"- Fractal dimension: **{details['fractal_dimension']:.4f}**")

        with col3:
            st.markdown("**Th√¥ng s·ªë kh√°c**")
            if details['centroid'][0] is not None:
                st.markdown(
                    f"- T√¢m v√πng t·ªïn th∆∞∆°ng: **({details['centroid'][0]}, {details['centroid'][1]})**")
            st.markdown(
                f"- Mean distance to centroid: **{details['mean_distance_to_centroid']:.2f}**")
            st.markdown(
                f"- Std distance to centroid: **{details['std_distance_to_centroid']:.2f}**")
            mean_color = details['mean_color']
            st.markdown(
                f"- M√†u trung b√¨nh v√πng t·ªïn th∆∞∆°ng (RGB): **({mean_color[0]:.1f}, {mean_color[1]:.1f}, {mean_color[2]:.1f})**")
            st.markdown(f"- Contrast: **{details['texture_contrast']:.4f}**")
            st.markdown(
                f"- Homogeneity: **{details['texture_homogeneity']:.4f}**")
            st.markdown(f"- Entropy: **{details['texture_entropy']:.4f}**")

        diagnosis_text = generate_diagnosis(query)
        st.subheader("üìù Ph√¢n t√≠ch b·ªánh l√Ω")
        st.markdown(diagnosis_text)

        st.subheader("üñºÔ∏è K·∫øt qu·∫£ ph√¢n ƒëo·∫°n t·ªïn th∆∞∆°ng")
        st.image(segmented_image_bytes,
                 caption="H√¨nh ·∫£nh k·∫øt qu·∫£ ph√¢n ƒëo·∫°n", use_container_width=True)
